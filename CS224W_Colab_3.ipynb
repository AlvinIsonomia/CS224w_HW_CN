{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **CS224W - Colab 3**\n",
    "\n",
    "## TODO \n",
    "- 看起来训练代码没有真的放在 GPU　上回来改一下好了～\n",
    "\n",
    "在 Colab 2 中，我们使用 PyTorch Geometric 中内置的 GCN 层，即`GCNConv`，构建 GNN 模型。 在此 Colab 中，我们将直接实现 **GraphSAGE** ([Hamilton 等 (2017)](https://arxiv.org/abs/1706.02216)) 和 **GAT**（[Veličković 等（2018)](https://arxiv.org/abs/1710.10903)) 层。 \n",
    "之后，在 CORA 数据集上运行我们的模型，这是一个标准的引文网络基准数据集。\n",
    "\n",
    "然后，我们将使用 [DeepSNAP](https://snap.stanford.edu/deepsnap/)，这是一个 Python 库，有助于对图进行高效的深度学习，在不同的设置中拆分图并应用数据集转换。\n",
    "\n",
    "最后，使用 DeepSNAP 的转导链接预测拆分功能（transductive link prediction split functionality），我们将在边属性预测（链接预测）任务上构建一个简单的 GNN 模型。\n",
    "\n",
    "**注意**：确保**依次运行每个部分中的所有单元格**，以便中间变量/包会延续到下一个单元格\n",
    "\n",
    "在 Colab 3 上玩得开心 0v0\n",
    "\n",
    "\n",
    "\n",
    "In Colab 2 we constructed GNN models by using PyTorch Geometric built in GCN layer, the `GCNConv`. In this Colab we will implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) and **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) layers directly. Then we will run our models on the CORA dataset, which is a standard citation network benchmark dataset.\n",
    "\n",
    "We will then use [DeepSNAP](https://snap.stanford.edu/deepsnap/), a Python library assisting efficient deep learning on graphs, to split the graphs in different settings and apply dataset transformations.\n",
    "\n",
    "At last, using DeepSNAP transductive link prediction split functionality, we will construct a simple GNN model on the edge property predition (link prediction) task.\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n",
    "\n",
    "Have fun on Colab 3 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSaetj53YnT6"
   },
   "source": [
    "# Device\n",
    "You might need to use GPU for this Colab.\n",
    "\n",
    "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67gOQITlCNQi"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J_m9l6OYCQZP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\\n!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\\n!pip install -q torch-geometric\\n!pip install -q git+https://github.com/snap-stanford/deepsnap.git'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip -q 指的是 quiet，不出意外就不通知你，所以得耐心等一下哦~\n",
    "\n",
    "# 急得话也可以把 -q 去掉\n",
    "\n",
    "'''!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q git+https://github.com/snap-stanford/deepsnap.git'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PRfgbfTjCRD_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoXlf4MtYrbz"
   },
   "source": [
    "# 1 GNN Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQy2RBfgYut4"
   },
   "source": [
    "## 实现 Layer Modules\n",
    "\n",
    "在 colab 2 中，我们在节点和图分类任务中使用 GCN 实现了一个网络。 但是，我们在 colab 2 中使用的 GCN 模块来自官方库。 对于这个问题，我们将为您提供一个通用的 Graph Neural Network Stack，您可以在其中插入您自己的 GraphSAGE 和 GAT 模块。\n",
    "\n",
    "我们将使用我们的实现来完成 CORA 上的节点分类，CORA 是一个标准的引文网络基准数据集。 在这个数据集中:\n",
    "- 节点对应于文档，\n",
    "- 边对应于无向引用。 \n",
    "\n",
    "每个节点都有一个类标签，节点特征是文档的 bag-or-words 表示的元素。\n",
    "\n",
    "对于 Cora 数据集，有：\n",
    "- 2708 个节点、\n",
    "- 5429 条边、\n",
    "- 7 个节点预测类\n",
    "- 每个节点 1433 个特征。\n",
    "\n",
    "## Implementing Layer Modules\n",
    "\n",
    "In colab 2, we implemented a network using GCN in node and graph classification tasks. However, the GCN module we used in colab 2 is from the official library. For this problem, we will provide you with a general Graph Neural Network Stack, where you'll be able to plugin your own modules of GraphSAGE and GATs. We will use our implementations to complete node classification on CORA, which is a standard citation network benchmark dataset. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node has a class label. The node features are elements of a bag-or-words representation of a document. For the Cora dataset, there are 2708 nodes, 5429 edges, 7 prediction classes for nodes, and 1433 features per node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4ne6Gw-CT5G"
   },
   "source": [
    "## GNN Stack Module\n",
    "\n",
    "下面是一个通用的 GNN Module，可以插入各种层，包括 **GraphSage**, **GAT** 等等。\n",
    "这个模块是为您提供的，而你自己的 **GraphSage** 和 **GAT** 层将作为 GNNStack 模块中的组件。\n",
    "\n",
    "## GNN Stack Module\n",
    "\n",
    "Below is the implementation for a general GNN Module that could plugin any layers, including **GraphSage**, **GAT**, etc. This module is provided for you, and you own **GraphSage** and **GAT** layers will function as components in the GNNStack Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ys8vZAFPCWWe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = self.build_conv_model(args.model_type) # GraphSage / GAT\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        # 后信息传递\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "\n",
    "    def build_conv_model(self, model_type):\n",
    "        if model_type == 'GraphSage':\n",
    "            return GraphSage\n",
    "        elif model_type == 'GAT':\n",
    "            '''\n",
    "            当使用 GAT，且 heads 的数量大于 1 时，需要需改卷积层（self.convs）输入和输出的维度，\n",
    "            以保下一层的输入维度是 num heads 乘上前一层的输出维度\n",
    "            提示：如果你想搞个 multiheads，你需要改动建立 self.convs 的 for-循环：\n",
    "            self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)),\n",
    "            并将后信息传递（post-message-passing）的第一个线性层改为 nn.Linear(hidden_dim * num_heads, hidden_dim)\n",
    "            '''\n",
    "            # When applying GAT with num heads > 1, one needs to modify the \n",
    "            # input and output dimension of the conv layers (self.convs),\n",
    "            # to ensure that the input dim of the next layer is num heads\n",
    "            # multiplied by the output dim of the previous layer.\n",
    "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
    "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
    "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
    "            return GAT\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "          \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb == True:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1) # 这个 dim 必须要指定好了\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "    # 上面的是负对数似然 NLL Loss\n",
    "    #https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syDtxjxoCZgq"
   },
   "source": [
    "## GraphSage 实现\n",
    "\n",
    "现在让我们开始实现我们自己的层！这部分是为了熟悉如何实现基于消息传递（Message Passing）的 Pytorch 层。您将实现 **forward**、**message** 和 **aggregate** 函数。\n",
    "\n",
    "通常，**forward** 函数是进行实际消息传递的地方。每次迭代中的所有逻辑都发生在 **forward** 中，我们将调用 **propagate** 函数将信息从邻居节点传播到中心节点。所以一般范式将是预处理 -> 传播 -> 后处理。\n",
    "\n",
    "回想一下我们在作业1中介绍的消息传递过程。**propagate** 进一步调用 **message** 将邻居节点的信息转化为消息，**aggregate** 将邻居节点的所有消息聚合为一个，**update** 在下一次迭代中进一步生成节点的嵌入。\n",
    "\n",
    "我们的实现与此略有不同，我们不会显式实现 **update**，而是将更新节点的逻辑放在 **forward** 函数中。更具体地说，信息传播后，我们可以进一步对 **propagate** 的输出进行一些操作。 **forward** 的输出正是当前迭代之后的嵌入。\n",
    "\n",
    "此外，传递给 **propagate()** 的张量可以通过将 _i 或 _j 附加到变量名称来映射到相应的节点 $i$ 和 $j$，例如 x_i 和 x_j。请注意，我们通常将 $i$ 称为聚合信息的中心节点，将 $j$ 称为相邻节点，因为这是最常见的表示法。\n",
    "\n",
    "请在评论（？）中找到更多详细信息。需要注意的一件事是我们正在向 GraphSage 添加**跳接**。形式上，我们模型的更新规则描述如下：\n",
    "\n",
    "\\begin{equation}\n",
    "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
    "\\end{equation}\n",
    "\n",
    "此外, 每一轮迭代之后都使用了 $\\ell$-2 正则化.\n",
    "\n",
    "为了正确地完成工作，我们必须了解不同的函数是如何相互作用的。 \n",
    "\n",
    "在 **propagate** 函数中，我们可以传入我们想要的任何参数。 例如，我们传入 $x$ 作为参数：\n",
    "\n",
    "... = propagate(..., $x$=($x_{central}$, $x_{neighbor}$), ...)\n",
    "\n",
    "其中 $x_{central}$ 与 $x_{neighbor}$ 表示来自 **central** 节点以及 **neighbor** 节点的特征。如果我们正在对中心与领域使用相同的表征， 那么 $x_{central}$ 与 $x_{neighbor}$ 应该是一样的.\n",
    "\n",
    "假设 $x_{central}$ 与 $x_{neighbor}$ 的形状皆为 N * d, 其中 N 为节点数,  d 为特征数.\n",
    "\n",
    "之后再消息（message）函数中，我们可接收名为 $x\\_i$ 和 $x\\_j$ 的参数. 通常 $x\\_i$ 表示 \"中心节点\", 而 $x\\_j$ 表示 \"邻居节点\". 注意这里两个参数的形状！$x\\_i$， $x\\_j$ 都是 E * d 大小的(**而不是 N!**). $x\\_i$ 通过查找我们在**propagate** 函数中传递的，将中心节点所有边的信息 $x_{central}$  concate 起来获得. \n",
    "类似地, $x\\_j$ 通过查找我们在**propagate** 函数中传递的，将邻居节点所有边的信息 $x_{neighbor}$ concate 起来获得。\n",
    "\n",
    "\n",
    "举个例子，假设有四个节点，因此 $x_{central}$ 与 $x_{neighbor}$ 的形状皆为 4 * d. 之后我们有两条边，(1, 2) 和 (3, 0). \n",
    "因此, $x\\_i$ 由 $[x_{central}[1]^T; x_{central}[3]^T]^T$ 获得, 而 $x\\_j$ 由 $[x_{neighbor}[2]^T; x_{neighbor}[0]^T]^T$ 获得\n",
    "\n",
    "<font color='red'> 不要在之后的问题中借鉴网上的实现！ </font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GraphSage Implementation\n",
    "\n",
    "\n",
    "Now let's start working on our own implementation of layers! This part is to get you familiar with how to implement Pytorch layer based on Message Passing. You will be implementing the **forward**, **message** and **aggregate** functions.\n",
    "\n",
    "Generally, the **forward** function is where the actual message passing is conducted. All logic in each iteration happens in **forward**, where we'll call **propagate** function to propagate information from neighbor nodes to central nodes.  So the general paradigm will be pre-processing -> propagate -> post-processing.\n",
    "\n",
    "Recall the process of message passing we introduced in homework 1. **propagate** further calls **message** which transforms information of neighbor nodes into messages, **aggregate** which aggregates all messages from neighbor nodes into one, and **update** which further generates the embedding for nodes in the next iteration.\n",
    "\n",
    "Our implementation is slightly variant from this, where we'll not explicitly implement **update**, but put the logic for updating nodes in **forward** function. To be more specific, after information is propagated, we can further conduct some operations on the output of **propagate**. The output of **forward** is exactly the embeddings after the current iteration.\n",
    "\n",
    "In addition, tensors passed to **propagate()** can be mapped to the respective nodes $i$ and $j$ by appending _i or _j to the variable name, .e.g. x_i and x_j. Note that we generally refer to $i$ as the central nodes that aggregates information, and refer to $j$ as the neighboring nodes, since this is the most common notation.\n",
    "\n",
    "Please find more details in the comments. One thing to note is that we're adding **skip connections** to our GraphSage. Formally, the update rule for our model is described as below:\n",
    "\n",
    "\\begin{equation}\n",
    "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
    "\\end{equation}\n",
    "\n",
    "For simplicity, we use mean aggregations where:\n",
    "\n",
    "\\begin{equation}\n",
    "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
    "\\end{equation}\n",
    "\n",
    "Additionally, $\\ell$-2 normalization is applied after each iteration.\n",
    "\n",
    "In order to complete the work correctly, we have to understand how the different functions interact with each other. In **propagate** we can pass in any parameters we want. For example, we pass in $x$ as an parameter:\n",
    "\n",
    "... = propagate(..., $x$=($x_{central}$, $x_{neighbor}$), ...)\n",
    "\n",
    "Here $x_{central}$ and $x_{neighbor}$ represent the features from **central** nodes and from **neighbor** nodes. If we're using the same representations from central and neighbor, then $x_{central}$ and $x_{neighbor}$ could be identical.\n",
    "\n",
    "Suppose $x_{central}$ and $x_{neighbor}$ are both of shape N * d, where N is number of nodes, and d is dimension of features.\n",
    "\n",
    "Then in message function, we can take parameters called $x\\_i$ and $x\\_j$. Usually $x\\_i$ represents \"central nodes\", and $x\\_j$ represents \"neighbor nodes\". Pay attention to the shape here: $x\\_i$ and $x\\_j$ are both of shape E * d (**not N!**). $x\\_i$ is obtained by concatenating the embeddings of central nodes of all edges through lookups from $x_{central}$ we passed in propagate. Similarly, $x\\_j$ is obtained by concatenating the embeddings of neighbor nodes of all edges through lookups from $x_{neighbor}$ we passed in propagate.\n",
    "\n",
    "Let's look at an example. Suppose we have 4 nodes, so $x_{central}$ and $x_{neighbor}$ are of shape 4 * d. We have two edges (1, 2) and (3, 0). Thus, $x\\_i$ is obtained by $[x_{central}[1]^T; x_{central}[3]^T]^T$, and $x\\_j$ is obtained by $[x_{neighbor}[2]^T; x_{neighbor}[0]^T]^T$\n",
    "\n",
    "<font color='red'>For the following questions, DON'T refer to any existing implementations online.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RwG4HqCFCaOD"
   },
   "outputs": [],
   "source": [
    "class GraphSage(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, normalize = True,\n",
    "                 bias = False, **kwargs):  \n",
    "        super(GraphSage, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Define the layers needed for the message and update functions below.\n",
    "        # self.lin_l is the linear transformation that you apply to embedding \n",
    "        #            for central node.\n",
    "        # self.lin_r is the linear transformation that you apply to aggregated \n",
    "        #            message from neighbors.\n",
    "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO: 实现 message 与 update 函数\n",
    "        self.lin_l 是对于中心节点嵌入的线性变换\n",
    "        self.lin_r 是对于邻居节点嵌入的线性变换\n",
    "        实现至多两行就行了，\n",
    "        '''\n",
    "        self.lin_l = Linear(in_channels, out_channels)\n",
    "        self.lin_r = Linear(in_channels, out_channels)\n",
    "        ############################################################################\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "        self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement message passing, as well as any post-processing (our update rule).\n",
    "        # 1. First call propagate function to conduct the message passing.\n",
    "        #    1.1 See there for more information: \n",
    "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "        #    1.2 We use the same representations for central (x_central) and \n",
    "        #        neighbor (x_neighbor) nodes, which means you'll pass x=(x, x) \n",
    "        #        to propagate.\n",
    "        # 2. Update our node embedding with skip connection.\n",
    "        # 3. If normalize is set, do L-2 normalization (defined in \n",
    "        #    torch.nn.functional)\n",
    "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO: 实现信息传递，以及任何的后处理，至多5行代码，超了也没事\n",
    "        1. 首先调用 propagate 函数以执行信息传递\n",
    "            1.1 参考 https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "            1.2 我们对于中心 (x_central) 与邻居 (x_neighbor) 的节点使用相同的表征，因此传播用 x=(x,x)\n",
    "        2. 用跳接更新节点嵌入\n",
    "        3. 如果设定了 normalize，那么使用 L2 正则化（torch.nn.functional 里有）\n",
    "        PS 其实我不太明白所谓的跳接是啥意思，这里先用大佬的实现……\n",
    "        '''\n",
    "        out=self.propagate(edge_index,x=(x,x),size=size)\n",
    "        x=self.lin_l(x)\n",
    "        out=self.lin_r(out)\n",
    "        out=out+x\n",
    "        if self.normalize:\n",
    "            out=F.normalize(out)\n",
    "        \n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your message function here.\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO：至多一行代码，实现 message 函数\n",
    "        '''\n",
    "        out = x_j # ?\n",
    "        \n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "\n",
    "        out = None\n",
    "\n",
    "        # The axis along which to index number of nodes.\n",
    "        #node_dim 是 PyG MessagePassing的参数：indicates along which axis to propagate.\n",
    "        node_dim = self.node_dim\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your aggregate function here.\n",
    "        # See here as how to use torch_scatter.scatter: \n",
    "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO：实现你的 aggregate 函数。参考 torch_scatter.scatter 的官方文档:\n",
    "        https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
    "        '''\n",
    "        out = torch_scatter.scatter(inputs, index, node_dim,\n",
    "                                    dim_size = dim_size, reduce = 'mean')\n",
    "\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjcfF3RACdLD"
   },
   "source": [
    "## GAT Implementation\n",
    "\n",
    "Attention mechanisms have become the state-of-the-art in many sequence-based tasks such as machine translation and learning sentence representations. One of the major benefits of attention-based mechanisms is their ability to focus on the most relevant parts of the input to make decisions. In this problem, we will see how attention mechanisms can be used to perform node classification of graph-structured data through the usage of Graph Attention Networks (GATs).\n",
    "\n",
    "The building block of the Graph Attention Network is the graph attention layer, which is a variant of the aggregation function . Let $N$ be the number of nodes and $F$ be the dimension of the feature vector for each node. The input to each graph attentional layer is a set of node features: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. The output of each graph attentional layer is a new set of node features, which may have a new dimension $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
    "\n",
    "We will now describe this transformation of the input features into higher-level features performed by each graph attention layer. First, a shared linear transformation parametrized by the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$ is applied to every node. Next, we perform self-attention on the nodes. We use a shared attentional mechanism:\n",
    "\\begin{equation} \n",
    "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
    "\\end{equation}\n",
    "\n",
    "This mechanism computes the attention coefficients that capture the importance of node $j$'s features to node $i$:\n",
    "\\begin{equation}\n",
    "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
    "\\end{equation}\n",
    "The most general formulation of self-attention allows every node to attend to all other nodes which drops all structural information. To utilize graph structure in the attention mechanisms, we can use masked attention. In masked attention, we only compute $e_{ij}$ for nodes $j \\in \\mathcal{N}_i$ where $\\mathcal{N}_i$ is some neighborhood of node $i$ in the graph.\n",
    "\n",
    "To easily compare coefficients across different nodes, we normalize the coefficients across $j$ using a softmax function:\n",
    "\\begin{equation}\n",
    "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
    "\\end{equation}\n",
    "\n",
    "For this problem, our attention mechanism $a$ will be a single-layer feedforward neural network parametrized by a weight vector $\\overrightarrow{a} \\in \\mathbb{R}^{F'}$, followed by a LeakyReLU nonlinearity (with negative input slope 0.2). Let $\\cdot^T$ represent transposition and $||$ represent concatenation. The coefficients computed by our attention mechanism may be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
    "\\end{equation}\n",
    "\n",
    "For the following questions, we denote $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...]$ and $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...]$.\n",
    "\n",
    "\n",
    "At every layer of GAT, after the attention coefficients are computed for that layer, the aggregation function can be computed by a weighted sum of neighborhood messages, where weights are specified by $\\alpha_{ij}$.\n",
    "\n",
    "Now, we use the normalized attention coefficients to compute a linear combination of the features corresponding to them. These aggregated features will serve as the final output features for every node.\n",
    "\n",
    "\\begin{equation}\n",
    "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
    "\\end{equation}\n",
    "\n",
    "To stabilize the learning process of self-attention, we use multi-head attention. To do this we use $K$ independent attention mechanisms, or ``heads'' compute output features as in the above equations. Then, we concatenate these output feature representations:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "where $||$ is concentation, $\\alpha_{ij}^{(k)}$ are the normalized attention coefficients computed by the $k$-th attention mechanism $(a^k)$, and $\\mathbf{W}^{(k)}$ is the corresponding input linear transformation's weight matrix. Note that for this setting, $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT 实现\n",
    "（翻译省去了一些和 GNN 无关的内容，不然太长）\n",
    "注意力机制现在是各类SOTA的基操，其好处在于可以关注输入最相关的内容并做出决策。\n",
    "本问题中，我们通过 Graph Attention Networks (GATs) 将看到注意力机制如何使用在图结构数据上的节点分类任务。\n",
    "\n",
    "GATs 的组成模块是图注意力层，它是 aggregation 函数的变体。令 $N$ 为节点数， $F$ 是每个节点特征的维度. 那么每个图注意力层的输入就是一个节点特征的集合: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. 每个图注意力层的输出则是一个新的节点特征集合, 而可能特征拥有一个新的维度 $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, 其中 $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
    "\n",
    "我们现在描述每个图注意力层是怎么把输入特征转换到高阶特征的。\n",
    "首先，每个节点上都进行一个公用的线性变换，其有参数矩阵 $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$. 之后，我们使用在每个节点上进行 self-attention. 我们使用的注意力机制也是共享的：\n",
    "\n",
    "\\begin{equation} \n",
    "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
    "\\end{equation}\n",
    "\n",
    "这个机制计算的注意力因子可以捕获节点 $j$ 的特征相对于节点 $i$ 的重要程度:\n",
    "\n",
    "\\begin{equation}\n",
    "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
    "\\end{equation}\n",
    "\n",
    "self-attention 最常见的形式允许每个节点和其他所有节点计算注意力，这就会丧失所有的结构信息。为了在注意力机制中使用结构信息，我们可以使用 masked attention。\n",
    "在 masked attention 中, 我们只计算 $e_{ij}$，其中 $j \\in \\mathcal{N}_i$ 而 $\\mathcal{N}_i$ 是图中节点 $i$ 的邻居.\n",
    "\n",
    "为了在不同的节点上更简单地比较注意力系数，我们使用了一个 softmax 函数来松弛化不同的 $j$ 对应的注意力因子:\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
    "\\end{equation}\n",
    "\n",
    "本问题的注意力机制 $a$ 是一个单层的前馈神经网络，有一个权重向量进行参数化 $\\overrightarrow{a} \\in \\mathbb{R}^{F'}$, 之后接上一个 LeakyReLU 非线性 (负斜率 0.2). 令 $\\cdot^T$ 表示转置， $||$ 表示concate. \n",
    "那么，我们的注意力机制的计算可以表示为：\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
    "\\end{equation}\n",
    "\n",
    "在后续的问题中，我们令 $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...]$， $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...]$.\n",
    "\n",
    "在 GAT 的每一层，该层的注意力系数计算之后，aggregation 函数可以由邻居信息的加权求和计算，其中权重为 $\\alpha_{ij}$.\n",
    "\n",
    "现在，我们使用归一化的注意力系数来计算与它们对应的特征的线性组合。 这些聚合特征将作为每个节点的最终输出特征。\n",
    "\n",
    "\\begin{equation}\n",
    "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
    "\\end{equation}\n",
    "\n",
    "为了稳定 self-attention 的学习过程，我们使用多头注意力。也就是使用 $K$ 个独立的注意力机制，或者 ``heads`` 计算输出特征，如上述等式。之后，我们将这些输出特征 concate 在一起，重新表征为：\n",
    "\n",
    "\\begin{equation}\n",
    "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "其中 $||$ 是拼接, $\\alpha_{ij}^{(k)}$ 是由第 $k$ 个注意力机制 $(a^k)$ 计算出的归一化注意力系数，$\\mathbf{W}^{(k)}$ 是对应输入的线性变换的权重矩阵. 注意，这里 $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$.\n",
    "\n",
    "\n",
    "\n",
    "torch_geometric的GAT[可以看这里](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gat_conv.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w4j45gTpCeXO"
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, heads = 2,\n",
    "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lin_l = None\n",
    "        self.lin_r = None\n",
    "        self.att_l = None\n",
    "        self.att_r = None\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Define the layers needed for the message functions below.\n",
    "        # self.lin_l is the linear transformation that you apply to embeddings \n",
    "        # BEFORE message passing.\n",
    "        # Pay attention to dimensions of the linear layers, since we're using \n",
    "        # multi-head attention.\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO: 在下面定义一些 message 函数需要的层\n",
    "        self.lin_l 是是在消息传递（message passing）“之前”用于嵌入的线性变换。\n",
    "        注意线性层的维度，因为我们用的是多头注意力\n",
    "        '''\n",
    "        self.lin_l = Linear(in_channels, heads * out_channels)\n",
    "        # 即之前的 W_l，这里的in_channels就是已经乘过heads的数字\n",
    "        ############################################################################\n",
    "\n",
    "        self.lin_r = self.lin_l\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
    "        # You have to deal with multi-head scenarios.\n",
    "        # Use nn.Parameter instead of nn.Linear\n",
    "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO: 定义之前笔记公式力的 \\overrightarrow{a_l/r}^T，这个注意力参数\n",
    "        你需要处理多头注意力的情况\n",
    "        在这里不能用 nn.Linear，要用 nn.Parameter !（2行代码）\n",
    "        '''\n",
    "        # 注意参数的维度设置\n",
    "        self.att_l = Parameter(torch.Tensor(1, heads, out_channels))  #a_l\n",
    "        self.att_r = Parameter(torch.Tensor(1, heads, out_channels))  #a_r     \n",
    "        ############################################################################\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "        nn.init.xavier_uniform_(self.att_l)\n",
    "        nn.init.xavier_uniform_(self.att_r)\n",
    "        #https://pytorch.org/docs/stable/_modules/torch/nn/init.html#xavier_uniform_\n",
    "\n",
    "    def forward(self, x, edge_index, size = None):\n",
    "        \n",
    "        H, C = self.heads, self.out_channels\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
    "        # 1. First apply linear transformation to node embeddings, and split that \n",
    "        #    into multiple heads. We use the same representations for source and\n",
    "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
    "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
    "        # 3. Call propagate function to conduct the message passing. \n",
    "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
    "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "        # 4. Transform the output back to the shape of N * d.\n",
    "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO（5行）: 实现消息传递，以及任何预处理和后处理（即我们的更新规则）。\n",
    "        1. 首先对节点嵌入应用线性变换，并将其拆分为多个头。 我们对源节点和目标节点使用相同的表示，\n",
    "        但应用不同的线性权重（W_l 和 W_r）\n",
    "        2. 计算中心节点 (alpha_l) 和邻居节点 (alpha_r) 的 alpha 向量。\n",
    "        3. 调用传播函数进行消息传递。\n",
    "            3.1 记得传递 alpha = (alpha_l, alpha_r) 作为参数。\n",
    "            3.2 更多信息参见：\n",
    "            https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "        4. 将输出变换回 N * d 的形状。\n",
    "        '''\n",
    "        x_l = self.lin_l(x).view(-1, H, C)\n",
    "        x_r = self.lin_r(x).view(-1, H, C) # N × H × C\n",
    "        alpha_l = (x_l * self.att_l).sum(axis = 1) # * 是逐元素乘法。sum的维度是H（聚合）。\n",
    "        #alpha_l就是a^T * Wl * hi\n",
    "        alpha_r = (x_r * self.att_r).sum(axis=1)\n",
    "        out = self.propagate(edge_index, x=(x_l, x_r), alpha=(alpha_l, alpha_r),size=size).view(-1, H * C) #N*D(D=H*C)       \n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your message function. Putting the attention in message \n",
    "        # instead of in update is a little tricky.\n",
    "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
    "        #    and apply leaky Relu.\n",
    "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use \n",
    "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
    "        # 3. Apply dropout to attention weights (alpha).\n",
    "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
    "        #    should be of shape E * H * d.\n",
    "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
    "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
    "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO（~5行）: 实现函数，将 attention 放到 message 而不是 update 力稍微有点难\n",
    "        1. 使用 alpha_i 和 alhpa_j 计算最终的注意力权重，并加 leakyReLU\n",
    "        2. 对所有节点的邻居节点们进行 softmax, 作为一个完整性检验，输出形状应该是 E * H * d\n",
    "        3. 对注意力权重 (alpha) 进行 dropout\n",
    "        4. 将嵌入和注意力权重相乘。作为完整性检验，输出的形状应该还是 E * H * d\n",
    "        5. ptr (LongTensor，可选)：如果有的话，基于用 CSR representation 筛选出的输入计算 softmax\n",
    "        你可以很简单的把他传入 softmax\n",
    "        '''\n",
    "        alpha = alpha_i + alpha_j\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        #https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch-geometric-utils\n",
    "        #https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/utils/softmax.py\n",
    "        #没仔细看，反正参数是这些参数\n",
    "        \n",
    "        alpha = F.dropout(alpha, p = self.dropout, training = self.training).unsqueeze(1)\n",
    "        # .unsqueeze(1) 将 alpha 从 E * d 转化为 E * 1 * d\n",
    "        out = x_j * alpha # E * H * d\n",
    "        ############################################################################\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def aggregate(self, inputs, index, dim_size = None):\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: Your code here! \n",
    "        # Implement your aggregate function here.\n",
    "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
    "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
    "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "        '''\n",
    "        TODO(~1行)：实现你的 aggregate 函数\n",
    "        torch_scatter.scatter使用指南：https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
    "        注意，'reduce' 参数和 GraphSage 使用的不同\n",
    "        '''\n",
    "        out = torch_scatter.scatter(inputs, index, dim = self.node_dim, \n",
    "                                    dim_size = dim_size, reduce = 'sum')\n",
    "\n",
    "        ############################################################################\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2dkgSuWCheU"
   },
   "source": [
    "## Building Optimizers\n",
    "\n",
    "This function has been implemented for you. **For grading purposes please use the default Adam optimizer**, but feel free to play with other types of optimizers on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2dkgSuWCheU"
   },
   "source": [
    "## 搭建 Optimizers\n",
    "\n",
    "这个函数已经给你写好了。反正你也不用算分，这么多种随便 optimzier 都可以随便用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f_TIQ8NPCjBP"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBYdWFwYCkwY"
   },
   "source": [
    "## Training and Testing\n",
    "\n",
    "Here we provide you with the functions to train and test. **Please do not modify this part for grading purposes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBYdWFwYCkwY"
   },
   "source": [
    "## 训练与测试\n",
    "\n",
    "训练测试代码都写好了，没必要不需要改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_tZMWRc8CmGg"
   },
   "outputs": [],
   "source": [
    "# 加个tqdm 不知道怎么跑的这么慢\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    \n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['train_mask'].numpy()))\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                            args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    for epoch in range(args.epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            test_accs.append(test_acc)\n",
    "        else:\n",
    "            test_accs.append(test_accs[-1])\n",
    "    return test_accs, losses\n",
    "\n",
    "def test(loader, model, is_validation=True):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "    return correct / total\n",
    "  \n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7-h7jIsCns4"
   },
   "source": [
    "## Let's Start the Training!\n",
    "\n",
    "We will be working on the CORA dataset on node-level classification.\n",
    "\n",
    "This part is implemented for you. **For grading purposes, please do not modify the default parameters.** However, feel free to play with different configurations just for fun!\n",
    "\n",
    "**Submit your best accuracy and loss on Gradescope.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7-h7jIsCns4"
   },
   "source": [
    "## 训练开始！\n",
    "\n",
    "我们将在 CORA 数据集上进行一次节点分类。\n",
    "\n",
    "这个部分也给你写好了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qe9B45l9Cpz2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for args in [\n",
    "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "        for model in ['GraphSage', 'GAT']:\n",
    "            args.model_type = model\n",
    "            # Match the dimension.\n",
    "            if model == 'GAT':\n",
    "                args.heads = 2\n",
    "            else:\n",
    "                args.heads = 1\n",
    "\n",
    "            if args.dataset == 'cora':\n",
    "                dataset = Planetoid(root='./datasets/cora', name='Cora')\n",
    "            else:\n",
    "                raise NotImplementedError(\"Unknown dataset\") \n",
    "            test_accs, losses = train(dataset, args) \n",
    "\n",
    "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
    "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "\n",
    "            plt.title(dataset.name)\n",
    "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
    "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHELqjARZ1W5"
   },
   "source": [
    "## Question 1.1: What is the maximum accuracy you could get on test set for GraphSage? (10 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlCtBEBLMBkR"
   },
   "source": [
    "## Question 1.2: What is the maximum accuracy you could get on test set for GAT? (10 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# 2 DeepSNAP Basics\n",
    "\n",
    "In previous Colabs we used both of graph class (NetworkX) and tensor (PyG) representations of graphs separately. The graph class `nx.Graph` provides rich analysis and manipulation functionalities, such as the clustering coefficient and PageRank. To feed the graph into the model, we need to transform the graph into tensor representations including edge tensor `edge_index` and node attributes tensors `x` and `y`. But only using tensors (as the graphs formatted in PyG `datasets` and `data`) will make many graph manipulations and analysis less efficient and harder. So, in this Colab we will use DeepSNAP which combines both representations and offers a full pipeline for GNN training / validation / testing.\n",
    "\n",
    "\n",
    "In general, [DeepSNAP](https://github.com/snap-stanford/deepsnap) is a Python library to assist efficient deep learning on graphs. DeepSNAP features in its support for flexible graph manipulation, standard pipeline, heterogeneous graphs and simple API.\n",
    "\n",
    "1. DeepSNAP is easy to be used for the sophisticated graph manipulations, such as feature computation, pretraining, subgraph extraction etc. during/before the training.\n",
    "2. In most frameworks, standard pipelines for node, edge, link, graph-level tasks under inductive or transductive settings are left to the user to code. In practice, there are additional design choices involved (such as how to split dataset for link prediction). DeepSNAP provides such a standard pipeline that greatly saves repetitive coding efforts, and enables fair comparision for models.\n",
    "3. Many real-world graphs are heterogeneous graphs. But packages support for heterogeneous graphs, including data storage and flexible message passing, is lacking. DeepSNAP provides an efficient and flexible heterogeneous graph that supports both the node and edge heterogeneity.\n",
    "\n",
    "[DeepSNAP](https://github.com/snap-stanford/deepsnap) is a newly released project and it is still under development. If you find any bugs or have any improvement ideas, feel free to raise issues or create pull requests on the GitHub directly :)\n",
    "\n",
    "In this Colab, we will focus on DeepSNAP graph manipulations and splitting settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf7vUmdNKCjA"
   },
   "source": [
    "# 2 DeepSNAP 基础知识\n",
    "\n",
    "在之前的 Colab 中，对于一张图，我们分别使用了图类 (NetworkX) 和张量 (PyG) 表示。\n",
    "\n",
    "图类 `nx.Graph` 提供了丰富的分析和操作功能，例如聚类系数和 PageRank。要将图输入模型，我们需要将图转换为张量表示，包括边张量 `edge_index` 和节点属性张量 `x `和 `y`。但仅使用张量（如在 PyG `datasets` 和 `data` 中格式化的图形）会使许多图形操作和分析的效率降低和困难。因此，在这个 Colab 中，我们将使用 DeepSNAP，它结合了两种表示并为 GNN 训练/验证/测试提供完整的管道。\n",
    "\n",
    "\n",
    "总的来说，[DeepSNAP](https://github.com/snap-stanford/deepsnap) 是一个 Python 库，用于辅助高效的图深度学习。 DeepSNAP 支持灵活的图形操作、标准管道、异构图形和简单的 API。\n",
    "\n",
    "1. DeepSNAP 易于在训练期间/之前用于复杂的图操作，例如特征计算、预训练、子图提取等。\n",
    "2. 在大多数框架中，归纳或转导 (inductive or transductive) 设置下的节点、边、链接、图级任务的标准管道留给用户编码。在实践中，还涉及其他设计选择（例如如何拆分数据集以进行链接预测）。 DeepSNAP 提供了这样一个标准管道，大大节省了重复编码工作，并实现了模型的公平比较。\n",
    "3. 许多现实世界的图是异构图。但是缺乏对异构图的包支持，包括数据存储和灵活的消息传递。 DeepSNAP 提供了一个高效灵活的异构图，支持节点和边异构。\n",
    "\n",
    "[DeepSNAP](https://github.com/snap-stanford/deepsnap) 是一个新发布的项目，还在开发中。如果您发现任何错误或有任何改进想法，请随时在 GitHub 上提出问题或创建拉取请求:)\n",
    "\n",
    "在此 Colab 中，我们将重点介绍 DeepSNAP 图操作和拆分设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20SvvngpQmmQ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfbBVFmAQlwz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def visualize(G, color_map=None, seed=123):\n",
    "    if color_map is None:\n",
    "        color_map = '#c92506'\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    nodes = nx.draw_networkx_nodes(G, pos=nx.spring_layout(G, seed=seed), \\\n",
    "                                 label=None, node_color=color_map, node_shape='o', node_size=150)\n",
    "    edges = nx.draw_networkx_edges(G, pos=nx.spring_layout(G, seed=seed), alpha=0.5)\n",
    "    if color_map is not None:\n",
    "        plt.scatter([],[], c='#c92506', label='Nodes with label 0', edgecolors=\"black\", s=140)\n",
    "        plt.scatter([],[], c='#fcec00', label='Nodes with label 1', edgecolors=\"black\", s=140)\n",
    "        plt.legend(prop={'size': 13}, handletextpad=0)\n",
    "    nodes.set_edgecolor('black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-o1P3r6hr2"
   },
   "source": [
    "## DeepSNAP Graph\n",
    "\n",
    "The `deepsnap.graph.Graph` class is the core class of DeepSNAP. It not only represents a graph in tensor format but also references to a graph object from graph manipulation package.\n",
    "\n",
    "Currently DeepSNAP supports [NetworkX](https://networkx.org/) and [Snap.py](https://snap.stanford.edu/snappy/doc/index.html) as the back end graph manipulation package.\n",
    "\n",
    "In this Colab, we will use the NetworkX as the back end graph manipulation package.\n",
    "\n",
    "=============================================================\n",
    "\n",
    "Lets first try to convert a simple random NetworkX graph to a DeepSNAP graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ispq_lIoJl_z"
   },
   "source": [
    "## DeepSNAP 图\n",
    "\n",
    "`deepsnap.graph.Graph` 类是 DeepSNAP 的核心类。 它不仅表示张量格式的图形，而且还引用了图形操作包中的图形对象。\n",
    "\n",
    "目前 DeepSNAP 支持 [NetworkX](https://networkx.org/) 和 [Snap.py](https://snap.stanford.edu/snappy/doc/index.html) 作为后端图形操作包。\n",
    "\n",
    "在这个 Colab 中，我们将使用 NetworkX 作为后端图形操作包。\n",
    "\n",
    "==================================================================\n",
    "\n",
    "让我们先试着将一个简单的随机 NetworkX 图转化为一个 DeepSNAP 图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT5qca3x6XpG"
   },
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "p = 0.05\n",
    "seed = 100\n",
    "\n",
    "# Generate a networkx random graph\n",
    "G = nx.gnp_random_graph(num_nodes, p, seed=seed)\n",
    "\n",
    "# Generate some random node features and labels\n",
    "node_feature = {node : torch.rand([5, ]) for node in G.nodes()}\n",
    "node_label = {node : torch.randint(0, 2, ()) for node in G.nodes()}\n",
    "\n",
    "# Set the random features and labels to G\n",
    "nx.set_node_attributes(G, node_feature, name='node_feature')\n",
    "nx.set_node_attributes(G, node_label, name='node_label')\n",
    "\n",
    "# Print one node example\n",
    "for node in G.nodes(data=True):\n",
    "  print(node)\n",
    "  break\n",
    "\n",
    "color_map = ['#c92506' if node[1]['node_label'].item() == 0 else '#fcec00' for node in G.nodes(data=True)]\n",
    "\n",
    "# Visualize the graph\n",
    "visualize(G, color_map=color_map)\n",
    "\n",
    "# Transform the networkx graph into the deepsnap graph\n",
    "graph = Graph(G)\n",
    "\n",
    "# Print out the general deepsnap graph information\n",
    "print(graph)\n",
    "\n",
    "# DeepSNAP will convert node attributes to tensors\n",
    "# Notice the type of tensors\n",
    "print(\"Node feature (node_feature) has shape {} and type {}\".format(graph.node_feature.shape, graph.node_feature.dtype))\n",
    "print(\"Node label (node_label) has shape {} and type {}\".format(graph.node_label.shape, graph.node_label.dtype))\n",
    "\n",
    "# DeepSNAP will also generate the edge_index tensor\n",
    "print(\"Edge index (edge_index) has shape {} and type {}\".format(graph.edge_index.shape, graph.edge_index.dtype))\n",
    "\n",
    "# Different from only storing tensors, deepsnap graph also references to the networkx graph\n",
    "# We will discuss why the reference will be helpful later\n",
    "print(\"The DeepSNAP graph has {} as the internal manupulation graph\".format(type(graph.G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNMbc307KOQD"
   },
   "source": [
    "In DeepSNAP we have three levels of attributes. In this example, we have the **node level** attributes including `node_feature` and `node_label`. The other two levels of attributes are graph and edge attributes. The usage is similar to the node level one except that the feature becomes `edge_feature` or `graph_feature` and label becomes `edge_label` or `graph_label` etc.\n",
    "\n",
    "==============================================\n",
    "\n",
    "Similar to the NetworkX graph, we can easily get some basic information of the graph through class properties directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8Xz58_Da0qL"
   },
   "source": [
    "在 DeepSNAP 中，我们有三个级别的属性。 在这个例子中，我们有 **节点级** 属性，包括 `node_feature` 和 `node_label`。 \n",
    "\n",
    "另外两个级别的属性是图和边属性。 用法与节点一级相似，只是特征变为 `edge_feature` 或 `graph_feature` ，标签变为 `edge_label` 或者 `graph_label` 等。\n",
    "\n",
    "======================================\n",
    "\n",
    "与 NetworkX 图类似，我们可以直接通过类属性轻松获取图的一些基本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLo4zWAoeg6S"
   },
   "outputs": [],
   "source": [
    "# Number of nodes\n",
    "print(\"The random graph has {} nodes\".format(graph.num_nodes))\n",
    "\n",
    "# Number of edges\n",
    "print(\"The random graph has {} edges\".format(graph.num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po7IaRmwblI5"
   },
   "source": [
    "DeepSNAP also provides functions that can automatically transform the PyG datasets into a list of DeepSNAP graphs.\n",
    "\n",
    "Here we transform the CORA dataset into a list of DeepSNAP graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFkg2kCgcFwR"
   },
   "outputs": [],
   "source": [
    "root = './tmp/cora'\n",
    "name = 'Cora'\n",
    "\n",
    "# The Cora dataset\n",
    "pyg_dataset= Planetoid(root, name)\n",
    "\n",
    "# PyG dataset to a list of deepsnap graphs\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "# Get the first deepsnap graph (CORA only has one graph)\n",
    "graph = graphs[0]\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLm5vVYMAP2x"
   },
   "source": [
    "## Question 2.1: What is the number of classes and number of features in the CORA graph? (5 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iF_Kyqr_JbY"
   },
   "outputs": [],
   "source": [
    "def get_num_node_classes(graph):\n",
    "  # TODO: Implement this function that takes a deepsnap graph object\n",
    "  # and return the number of node classes of that graph.\n",
    "\n",
    "  num_node_classes = 0\n",
    "\n",
    "  ############# Your code here #############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful\n",
    "  ## 2. DeepSNAP documentation might be useful https://snap.stanford.edu/deepsnap/modules/graph.html\n",
    "\n",
    "\n",
    "  ##########################################\n",
    "\n",
    "  return num_node_classes\n",
    "\n",
    "def get_num_node_features(graph):\n",
    "  # TODO: Implement this function that takes a deepsnap graph object\n",
    "  # and return the number of node features of that graph.\n",
    "\n",
    "  num_node_features = 0\n",
    "\n",
    "  ############# Your code here #############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. Colab autocomplete functionality might be useful\n",
    "  ## 2. DeepSNAP documentation might be useful https://snap.stanford.edu/deepsnap/modules/graph.html\n",
    "\n",
    "\n",
    "  ##########################################\n",
    "\n",
    "  return num_node_features\n",
    "\n",
    "num_node_classes = get_num_node_classes(graph)\n",
    "num_node_features = get_num_node_features(graph)\n",
    "print(\"{} has {} classes\".format(name, num_node_classes))\n",
    "print(\"{} has {} features\".format(name, num_node_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwKbzhHUAckZ"
   },
   "source": [
    "## DeepSNAP Dataset\n",
    "\n",
    "Now, lets talk about DeepSNAP dataset. A `deepsnap.dataset.GraphDataset` contains a list of `deepsnap.graph.Graph` objects. In addition to list of graphs, you can also specify what task the dataset will be used on, such as node level task (`task=node`), edge level task (`task=link_pred`) and graph level task (`task=graph`).\n",
    "\n",
    "It also contains many other useful parameters during initialization and other functinoalities. If you are interested, you can take a look at the [documentation](https://snap.stanford.edu/deepsnap/modules/dataset.html#deepsnap-graphdataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSidf9E0hn2s"
   },
   "source": [
    "Lets now use COX2 dataset which contains a list of graphs and specify the task to `graph` when we initialize the DeepSNAP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4kqUldyoaS_"
   },
   "outputs": [],
   "source": [
    "root = './tmp/cox2'\n",
    "name = 'COX2'\n",
    "\n",
    "# Load the dataset through PyG\n",
    "pyg_dataset = TUDataset(root, name)\n",
    "\n",
    "# Convert to a list of deepsnap graphs\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "# Convert list of deepsnap graphs to deepsnap dataset with specified task=graph\n",
    "dataset = GraphDataset(graphs, task='graph')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sCV3xJWCddX"
   },
   "source": [
    "## Question 2.2: What is the label of the graph (index 100 in the COX2 dataset)? (5 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIis9oTZAfs3"
   },
   "outputs": [],
   "source": [
    "def get_graph_class(dataset, idx):\n",
    "  # TODO: Implement this function that takes a deepsnap dataset object,\n",
    "  # the index of the graph in the dataset, and returns the class/label \n",
    "  # of the graph (in integer).\n",
    "\n",
    "  label = -1\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 line of code)\n",
    "  ## Note\n",
    "  ## 1. The label refers to the graph-level attribute\n",
    "\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return label\n",
    "\n",
    "graph_0 = dataset[0]\n",
    "print(graph_0)\n",
    "idx = 100\n",
    "label = get_graph_class(dataset, idx)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKhcVeAhCwoY"
   },
   "source": [
    "## Question 2.3: What is the number of edges for the graph (index 200 in the COX2 dataset)? (5 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5m2DOfhBtWv"
   },
   "outputs": [],
   "source": [
    "def get_graph_num_edges(dataset, idx):\n",
    "  # TODO: Implement this function that takes a deepsnap dataset object,\n",
    "  # the index of the graph in dataset, and returns the number of \n",
    "  # edges in the graph (in integer).\n",
    "\n",
    "  num_edges = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 lines of code)\n",
    "  ## Note\n",
    "  ## 1. You can use the class property directly\n",
    "\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_edges\n",
    "\n",
    "idx = 200\n",
    "num_edges = get_graph_num_edges(dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXa7yIG4E0Fp"
   },
   "source": [
    "# 3 DeepSNAP Advanced\n",
    "\n",
    "We have learned the basic use of DeepSNAP graph and dataset :)\n",
    "\n",
    "Lets move on to some more advanced functionalities.\n",
    "\n",
    "In this section we will use DeepSNAP for faeture computation and transductive/inductive splittings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5fsGBLY8cxa"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-jgRLiQ8cSj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnazPGGAJAZN"
   },
   "source": [
    "## Data Split in Graphs\n",
    "\n",
    "Data splitting in graphs can be much harder than that in CV or NLP.\n",
    "\n",
    "In general, the data splitting in graphs can be divided into two settings, **inductive** and **transductive**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9KG_MhqsWBp"
   },
   "source": [
    "## Inductive Split\n",
    "\n",
    "As what we have learned in the lecture, inductive setting will split multiple graphs into each training/valiation and test sets.\n",
    "\n",
    "Here is an example of DeepSNAP inductive splitting for a list of graphs in the graph level task (graph classification etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gpc6bTm3GF02"
   },
   "outputs": [],
   "source": [
    "root = './tmp/cox2'\n",
    "name = 'COX2'\n",
    "\n",
    "pyg_dataset = TUDataset(root, name)\n",
    "\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "# Here we specify the task as graph-level task such as graph classification\n",
    "task = 'graph'\n",
    "dataset = GraphDataset(graphs, task=task)\n",
    "\n",
    "# Specify transductive=False (inductive)\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(transductive=False, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(\"COX2 train dataset: {}\".format(dataset_train))\n",
    "print(\"COX2 validation dataset: {}\".format(dataset_val))\n",
    "print(\"COX2 test dataset: {}\".format(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWKQwa4WsgQp"
   },
   "source": [
    "## Transductive Split\n",
    "\n",
    "In transductive setting, the training /validation / test sets are on the same graph.\n",
    "\n",
    "Here we transductively split the CORA graph in the node level task. \n",
    "\n",
    "(Notice that in DeepSNAP default setting the split is random, but you can also make a fixed split by specifying `fixed_split=True` when loading the dataset from PyG or changing the `node_label_index` directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5OdxSg4sfyR"
   },
   "outputs": [],
   "source": [
    "root = './tmp/cora'\n",
    "name = 'Cora'\n",
    "\n",
    "pyg_dataset = Planetoid(root, name)\n",
    "\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "# Here we specify the task as node-level task such as node classification\n",
    "task = 'node'\n",
    "\n",
    "dataset = GraphDataset(graphs, task=task)\n",
    "\n",
    "# Specify we want the transductive splitting\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(\"Cora train dataset: {}\".format(dataset_train))\n",
    "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
    "print(\"Cora test dataset: {}\".format(dataset_test))\n",
    "\n",
    "print(\"Original Cora has {} nodes\".format(dataset.num_nodes[0]))\n",
    "\n",
    "# The nodes in each set can be find in node_label_index\n",
    "print(\"After the split, Cora has {} training nodes\".format(dataset_train[0].node_label_index.shape[0]))\n",
    "print(\"After the split, Cora has {} validation nodes\".format(dataset_val[0].node_label_index.shape[0]))\n",
    "print(\"After the split, Cora has {} test nodes\".format(dataset_test[0].node_label_index.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7ePKgM00lGE"
   },
   "source": [
    "## Edge Level Split\n",
    "\n",
    "Compared to the node and graph level splitting, edge level splitting is a little bit tricky ;)\n",
    "\n",
    "Usually in edge level splitting, we need to sample negative edges, split positive edges into different datasets, split training edges into message passing edges and supervision edges, and resample the negative edges during the training etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnzISX5RoiR6"
   },
   "source": [
    "### All Mode\n",
    "\n",
    "Now lets start with a simpler edge level splitting mode, the `edge_train_mode=\"all\"` mode in DeepSNAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D104xO6137n"
   },
   "outputs": [],
   "source": [
    "root = './tmp/cora'\n",
    "name = 'Cora'\n",
    "\n",
    "pyg_dataset = Planetoid(root, name)\n",
    "\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "# Specify task as link_pred for edge-level task\n",
    "task = 'link_pred'\n",
    "\n",
    "# Specify the train mode, \"all\" mode is default for deepsnap dataset\n",
    "edge_train_mode = \"all\"\n",
    "\n",
    "dataset = GraphDataset(graphs, task=task, edge_train_mode=edge_train_mode)\n",
    "\n",
    "# Transductive link prediction split\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(\"Cora train dataset: {}\".format(dataset_train))\n",
    "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
    "print(\"Cora test dataset: {}\".format(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GscopwOXC_Y7"
   },
   "source": [
    "In DeepSNAP, the indices of supervision edges are stored in `edge_label_index` tensor and the corresponding edge labels are stored in `edge_label` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJF8fZnA2eLR"
   },
   "outputs": [],
   "source": [
    "print(\"Original Cora graph has {} edges\".format(dataset[0].num_edges))\n",
    "print(\"Because Cora graph is undirected, the original edge_index has shape {}\".format(dataset[0].edge_index.shape))\n",
    "\n",
    "print(\"The training set has message passing edge index shape {}\".format(dataset_train[0].edge_index.shape))\n",
    "print(\"The training set has supervision edge index shape {}\".format(dataset_train[0].edge_label_index.shape))\n",
    "\n",
    "print(\"The validation set has message passing edge index shape {}\".format(dataset_val[0].edge_index.shape))\n",
    "print(\"The validation set has supervision edge index shape {}\".format(dataset_val[0].edge_label_index.shape))\n",
    "\n",
    "print(\"The test set has message passing edge index shape {}\".format(dataset_test[0].edge_index.shape))\n",
    "print(\"The test set has supervision edge index shape {}\".format(dataset_test[0].edge_label_index.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6BX-I_oEKQX"
   },
   "source": [
    "We can see that both training and validation sets have the same message passing edges (`edge_index`) in the `all` mode. Also, in training set, the postive supervision edges (`edge_label_index`) are same with the message passing edges. However, in the test set the message passing edges are the combination of message passing edges from training and validation sets.\n",
    "\n",
    "Notice that the `edge_label` and `edge_label_index` have included the negative edges (default number of negative edges is same with the number of positive edges).\n",
    "\n",
    "Now, lets implement a function that checks whether two edge index tensors are disjoint and explore more edge splitting properties by using that function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOZHDskbAKN6"
   },
   "source": [
    "## Question 3.1 - 3.5: Implement the function that checks whether two edge_index tensors are disjoint. Then answer the True/False questions below. (5 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgRYdyPp8EmO"
   },
   "outputs": [],
   "source": [
    "def edge_indices_disjoint(edge_index_1, edge_index_2):\n",
    "  # TODO: Implement this function that takes two edge index tensors,\n",
    "  # and returns whether these two edge index tensors are disjoint.\n",
    "  disjoint = None\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~5 lines of code)\n",
    "  ## Note\n",
    "  ## 1. Here disjoint means that there is no single edge belongs to either edge index tensors\n",
    "  ## 2. You do not need to consider the undirected case. For example, if edge_index_1 contains\n",
    "  ## edge (a, b) and edge_index_2 contains edge (b, a). We will treat them as disjoint in this\n",
    "  ## function.\n",
    "\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EL4ASIDDEIUf"
   },
   "outputs": [],
   "source": [
    "num_train_edges = dataset_train[0].edge_label_index.shape[1] // 2\n",
    "train_pos_edge_index = dataset_train[0].edge_label_index[:, :num_train_edges]\n",
    "train_neg_edge_index = dataset_train[0].edge_label_index[:, num_train_edges:]\n",
    "print(\"3.1 Training (supervision) positve and negative edges are disjoint = {}\"\\\n",
    "        .format(edge_indices_disjoint(train_pos_edge_index, train_neg_edge_index)))\n",
    "\n",
    "num_val_edges = dataset_val[0].edge_label_index.shape[1] // 2\n",
    "val_pos_edge_index = dataset_val[0].edge_label_index[:, :num_val_edges]\n",
    "val_neg_edge_index = dataset_val[0].edge_label_index[:, num_val_edges:]\n",
    "print(\"3.2 Validation (supervision) positve and negative edges are disjoint = {}\"\\\n",
    "        .format(edge_indices_disjoint(val_pos_edge_index, val_neg_edge_index)))\n",
    "\n",
    "num_test_edges = dataset_test[0].edge_label_index.shape[1] // 2\n",
    "test_pos_edge_index = dataset_test[0].edge_label_index[:, :num_test_edges]\n",
    "test_neg_edge_index = dataset_test[0].edge_label_index[:, num_test_edges:]\n",
    "print(\"3.3 Test (supervision) positve and negative edges are disjoint = {}\"\\\n",
    "        .format(edge_indices_disjoint(test_pos_edge_index, test_neg_edge_index)))\n",
    "\n",
    "print(\"3.4 Test (supervision) positve and validation (supervision) positve edges are disjoint = {}\"\\\n",
    "        .format(edge_indices_disjoint(test_pos_edge_index, val_pos_edge_index)))\n",
    "print(\"3.5 Validation (supervision) positve and training (supervision) positve edges are disjoint = {}\"\\\n",
    "        .format(edge_indices_disjoint(val_pos_edge_index, train_pos_edge_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jLoVN5ZBTuA"
   },
   "source": [
    "### Disjoint Mode\n",
    "\n",
    "Now lets look at a relatively more complex transductive edge split setting, which is the `edge_train_mode=\"disjoint\"` mode in DeepSNAP (also the transductive link prediction splitting talked in the lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Rqzfb-0BTBm"
   },
   "outputs": [],
   "source": [
    "edge_train_mode = \"disjoint\"\n",
    "\n",
    "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=edge_train_mode)\n",
    "orig_edge_index = dataset[0].edge_index\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(\n",
    "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "train_message_edge_index = dataset_train[0].edge_index\n",
    "train_sup_edge_index = dataset_train[0].edge_label_index\n",
    "val_sup_edge_index = dataset_val[0].edge_label_index\n",
    "test_sup_edge_index = dataset_test[0].edge_label_index\n",
    "\n",
    "print(\"The edge index of original graph has shape: {}\".format(orig_edge_index.shape))\n",
    "print(\"The edge index of training message edges has shape: {}\".format(train_message_edge_index.shape))\n",
    "print(\"The edge index of training supervision edges has shape: {}\".format(train_sup_edge_index.shape))\n",
    "print(\"The edge index of validation message edges has shape: {}\".format(dataset_val[0].edge_index.shape))\n",
    "print(\"The edge index of validation supervision edges has shape: {}\".format(val_sup_edge_index.shape))\n",
    "print(\"The edge index of test message edges has shape: {}\".format(dataset_test[0].edge_index.shape))\n",
    "print(\"The edge index of test supervision edges has shape: {}\".format(test_sup_edge_index.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUkBhiJNciol"
   },
   "source": [
    "You can see that the training / validation message passing edges and training supervision edges are splitted differently in those two modes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WKfRjqAJHtK"
   },
   "source": [
    "### Resample Negative Edges\n",
    "\n",
    "During each training iteration, we usually need to resample the negative edges.\n",
    "\n",
    "Below we print the training and validation sets negative edges in two training iterations.\n",
    "\n",
    "You should find that the negative edges in training set will be resampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMEbnx63JHWj"
   },
   "outputs": [],
   "source": [
    "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=\"disjoint\")\n",
    "datasets = {}\n",
    "follow_batch = []\n",
    "datasets['train'], datasets['val'], datasets['test'] = dataset.split(\n",
    "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
    "dataloaders = {\n",
    "  split: DataLoader(\n",
    "    ds, collate_fn=Batch.collate(follow_batch),\n",
    "    batch_size=1, shuffle=(split=='train')\n",
    "  )\n",
    "  for split, ds in datasets.items()\n",
    "}\n",
    "neg_edges_1 = None\n",
    "for batch in dataloaders['train']:\n",
    "  num_edges = batch.edge_label_index.shape[1] // 2\n",
    "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
    "  print(\"First iteration training negative edges:\")\n",
    "  print(neg_edges_1)\n",
    "  break\n",
    "neg_edges_2 = None\n",
    "for batch in dataloaders['train']:\n",
    "  num_edges = batch.edge_label_index.shape[1] // 2\n",
    "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
    "  print(\"Second iteration training negative edges:\")\n",
    "  print(neg_edges_2)\n",
    "  break\n",
    "\n",
    "neg_edges_1 = None\n",
    "for batch in dataloaders['val']:\n",
    "  num_edges = batch.edge_label_index.shape[1] // 2\n",
    "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
    "  print(\"First iteration validation negative edges:\")\n",
    "  print(neg_edges_1)\n",
    "  break\n",
    "neg_edges_2 = None\n",
    "for batch in dataloaders['val']:\n",
    "  num_edges = batch.edge_label_index.shape[1] // 2\n",
    "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
    "  print(\"Second iteration validation negative edges:\")\n",
    "  print(neg_edges_2)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEzqh7wEdrh0"
   },
   "source": [
    "If you are interested in more graph splitting settings, please refer to the DeepSNAP dataset [documentation](https://snap.stanford.edu/deepsnap/modules/dataset.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkrYyeSUI_9_"
   },
   "source": [
    "## Graph Transformation and Feature Computation\n",
    "\n",
    "The other DeepSNAP core functionality is graph transformation / feature computation.\n",
    "\n",
    "In DeepSNAP, we divide graph transformation / feature computation into two different types. One is the transformation before training (transform the whole dataset before training directly) and another one is the transformation during training (transform batches of graphs).\n",
    "\n",
    "Here is an example that uses NetworkX back end to calculate the PageRank value and update the value to tensors before the training (transform the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnAVbZINLZ4I"
   },
   "outputs": [],
   "source": [
    "def pagerank_transform_fn(graph):\n",
    "\n",
    "  # Get the referenced networkx graph\n",
    "  G = graph.G\n",
    "\n",
    "  # Calculate the pagerank by using networkx\n",
    "  pr = nx.pagerank(G)\n",
    "\n",
    "  # Transform the pagerank values to tensor\n",
    "  pr_feature = torch.tensor([pr[node] for node in range(graph.num_nodes)], dtype=torch.float32)\n",
    "  pr_feature = pr_feature.view(graph.num_nodes, 1)\n",
    "\n",
    "  # Concat the pagerank values to the node feature\n",
    "  graph.node_feature = torch.cat([graph.node_feature, pr_feature], dim=-1)\n",
    "\n",
    "root = './tmp/cox2'\n",
    "name = 'COX2'\n",
    "pyg_dataset = TUDataset(root, name)\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "dataset = GraphDataset(graphs, task='graph')\n",
    "print(\"Number of features before transformation: {}\".format(dataset.num_node_features))\n",
    "dataset.apply_transform(pagerank_transform_fn, update_tensor=False)\n",
    "print(\"Number of features after transformation: {}\".format(dataset.num_node_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHByE87SQkUw"
   },
   "source": [
    "## Question 3.6: Implement the transformation below and report the clustering coefficient of the node (index 3) of the graph (index 406) in the COX2 dataset. Rounded the answer to two decimal places. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNEjfOZRNjYb"
   },
   "outputs": [],
   "source": [
    "def cluster_transform_fn(graph):\n",
    "  # TODO: Implement this function that takes an deepsnap graph object,\n",
    "  # transform the graph by adding nodes clustering coefficient into the \n",
    "  # graph.node_feature\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~5 lines of code)\n",
    "  ## Note\n",
    "  ## 1. Compute the clustering coefficient value for each node and\n",
    "  ## concat them to the last dimension of graph.node_feature\n",
    "\n",
    "\n",
    "  #########################################\n",
    "\n",
    "root = './cox2'\n",
    "name = 'COX2'\n",
    "pyg_dataset = TUDataset(root, name)\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "dataset = GraphDataset(graphs, task='graph')\n",
    "\n",
    "# Transform the dataset\n",
    "dataset.apply_transform(cluster_transform_fn, update_tensor=False)\n",
    "\n",
    "node_idx = 3\n",
    "graph_idx = 406\n",
    "node_feature = dataset[graph_idx].node_feature\n",
    "\n",
    "print(\"The node has clustering coefficient: {}\".format(round(node_feature[node_idx][-1].item(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P5Ig7XaPYzp"
   },
   "source": [
    "Apart from transforming the dataset, DeepSNAP can also transform the graph (usually the `deepsnap.batch.Batch`) during each training iteration.\n",
    "\n",
    "Also, DeepSNAP supports the synchronization of the transformation between the referenced graph objects and tensor representations. For example, you can just update the NetworkX graph object in the transform function, and by specifying `update_tensor=True` the internal tensor representations will be automatically updated.\n",
    "\n",
    "For more information, please refer to the DeepSNAP [documentation](https://snap.stanford.edu/deepsnap/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-YLYMLFQYqp"
   },
   "source": [
    "# 4 Edge Level Prediction\n",
    "\n",
    "From last section, we know how DeepSNAP transductive split the edges in the link prediction task.\n",
    "\n",
    "Now lets use DeepSNAP and PyG together to implement a edge level prediction (link prediction) model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrKCNtvERypQ"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepsnap.graph import Graph\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class LinkPredModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.2):\n",
    "        super(LinkPredModel, self).__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, num_classes)\n",
    "\n",
    "        self.loss_fn = None\n",
    "\n",
    "        ############# Your code here #############\n",
    "        ## (~1 line of code)\n",
    "        ## Note\n",
    "        ## 1. Initialize the loss function to BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        node_feature, edge_index, edge_label_index = batch.node_feature, batch.edge_index, batch.edge_label_index\n",
    "        \n",
    "        ############# Your code here #############\n",
    "        ## (~6 line of code)\n",
    "        ## Note\n",
    "        ## 1. Feed the node feature into the first conv layer\n",
    "        ## 2. Add a ReLU after the first conv layer\n",
    "        ## 3. Add dropout after the ReLU (with probability self.dropout)\n",
    "        ## 4. Feed the output to the second conv layer\n",
    "        ## 5. Select the embeddings of the source nodes and destination nodes\n",
    "        ## by using the edge_label_index and compute the similarity of each pair\n",
    "        ## by dot product\n",
    "\n",
    "        \n",
    "        ##########################################\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def loss(self, pred, link_label):\n",
    "        return self.loss_fn(pred, link_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuKbGFOu1Ka8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def train(model, dataloaders, optimizer, args):\n",
    "    val_max = 0\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in range(1, args[\"epochs\"]):\n",
    "        for i, batch in enumerate(dataloaders['train']):\n",
    "            \n",
    "            batch.to(args[\"device\"])\n",
    "\n",
    "            ############# Your code here #############\n",
    "            ## (~6 lines of code)\n",
    "            ## Note\n",
    "            ## 1. Zero grad the optimizer\n",
    "            ## 2. Compute loss and backpropagate\n",
    "            ## 3. Update the model parameters\n",
    "\n",
    "\n",
    "            ##########################################\n",
    "\n",
    "            log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {}'\n",
    "            score_train = test(model, dataloaders['train'], args)\n",
    "            score_val = test(model, dataloaders['val'], args)\n",
    "            score_test = test(model, dataloaders['test'], args)\n",
    "\n",
    "            print(log.format(epoch, score_train, score_val, score_test, loss.item()))\n",
    "            if val_max < score_val:\n",
    "                val_max = score_val\n",
    "                best_model = copy.deepcopy(model)\n",
    "    return best_model\n",
    "\n",
    "def test(model, dataloader, args):\n",
    "    model.eval()\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    ############# Your code here #############\n",
    "    ## (~5 lines of code)\n",
    "    ## Note\n",
    "    ## 1. Loop through batches in the dataloader\n",
    "    ## 2. Feed the batch to the model\n",
    "    ## 3. Feed the model output to sigmoid\n",
    "    ## 4. Compute the ROC-AUC score by using sklearn roc_auc_score function\n",
    "    ## 5. Edge labels are stored in batch.edge_label\n",
    "\n",
    "    \n",
    "    ##########################################\n",
    " \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTKWYX1b33V3"
   },
   "outputs": [],
   "source": [
    "# Please don't change any parameters\n",
    "args = {\n",
    "    \"device\" : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \"hidden_dim\" : 128,\n",
    "    \"epochs\" : 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Klw_xYnE27xQ"
   },
   "outputs": [],
   "source": [
    "pyg_dataset = Planetoid('./tmp/cora', 'Cora')\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
    "\n",
    "dataset = GraphDataset(\n",
    "        graphs,\n",
    "        task='link_pred',\n",
    "        edge_train_mode=\"disjoint\"\n",
    "    )\n",
    "datasets = {}\n",
    "datasets['train'], datasets['val'], datasets['test']= dataset.split(\n",
    "            transductive=True, split_ratio=[0.85, 0.05, 0.1])\n",
    "input_dim = datasets['train'].num_node_features\n",
    "num_classes = datasets['train'].num_edge_labels\n",
    "\n",
    "model = LinkPredModel(input_dim, args[\"hidden_dim\"], num_classes).to(args[\"device\"])\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "dataloaders = {split: DataLoader(\n",
    "            ds, collate_fn=Batch.collate([]),\n",
    "            batch_size=1, shuffle=(split=='train'))\n",
    "            for split, ds in datasets.items()}\n",
    "best_model = train(model, dataloaders, optimizer, args)\n",
    "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
    "best_train_roc = test(best_model, dataloaders['train'], args)\n",
    "best_val_roc = test(best_model, dataloaders['val'], args)\n",
    "best_test_roc = test(best_model, dataloaders['test'], args)\n",
    "print(log.format(best_train_roc, best_val_roc, best_test_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5brlsKElP0_"
   },
   "source": [
    "## Question 4: What is the maximum ROC-AUC score you could get for the best_model on test set? (13 points)\n",
    "\n",
    "Submit your answers on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7JXsMTBgeOI"
   },
   "source": [
    "# Submission\n",
    "\n",
    "In order to get credit, you must go submit your answers on Gradescope.\n",
    "\n",
    "Also, you need to submit the `ipynb` file of Colab 3, by clicking `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CS224W - Colab 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
